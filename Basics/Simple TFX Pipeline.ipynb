{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple TFX Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOTW0qQiDJ3dkbphvjADs36",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satwikram/Tensorflow-For-Production/blob/main/Basics/Simple%20TFX%20Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLYtiM39uUE-"
      },
      "source": [
        "### Author: Satwik Ram K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KCpjqKQua2Y"
      },
      "source": [
        "### Upgrade Pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjtqosdYt8FR",
        "outputId": "c42442ec-a7cf-45b0-9863-48270d244b17"
      },
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install -q --upgrade pip\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 23.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 11.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 6.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |████                            | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 296kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 307kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 317kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 337kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 348kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 358kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 368kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 378kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 389kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 399kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 409kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 419kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 450kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 460kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 471kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 481kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 491kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 501kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 512kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 522kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 532kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 542kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 552kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 563kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 573kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 593kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 604kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 614kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 624kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 634kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 645kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 655kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 665kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 675kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 686kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 696kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 706kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 716kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 727kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 737kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 747kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 757kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 768kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 778kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 788kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 798kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 808kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 819kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 829kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 839kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 849kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 860kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 870kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 880kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 890kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 901kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 911kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 921kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 931kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 942kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 952kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 962kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 972kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 983kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 993kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.0MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6MB 5.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KG8eDVZucK-"
      },
      "source": [
        "### Install TFX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcM4LnneuXCP"
      },
      "source": [
        "!pip install -q -U --use-deprecated=legacy-resolver tfx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UqmC6gFvXxe"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IpjwQdxu7b_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tfx\n",
        "from absl import logging\n",
        "import urllib.request\n",
        "import tempfile\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTD7kNM3vc37"
      },
      "source": [
        "### Set up variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyaKENsWvjEY"
      },
      "source": [
        "PIPELINE_NAME = 'penguin-simple'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw-VzPy9vqYZ"
      },
      "source": [
        "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3bwkxJQvwQg"
      },
      "source": [
        "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j8Tog7pwDez"
      },
      "source": [
        "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKkonM6-wfHz"
      },
      "source": [
        "logging.set_verbosity(logging.INFO)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snLhMuMrxGZV"
      },
      "source": [
        "### Create Temp Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpiEpPgxwinX"
      },
      "source": [
        "DATA_ROOT = tempfile.mkdtemp(prefix = 'tfx-data') # Create a temporary directory."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jocx65JUxUa6"
      },
      "source": [
        "data_url = \"https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/penguins_processed.csv\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQWbv1sKxbcA"
      },
      "source": [
        "data_filepath = os.path.join(DATA_ROOT, \"data.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nCreLTSxgAw",
        "outputId": "8e4c1476-987b-40a6-deee-0a4eee127bc1"
      },
      "source": [
        "urllib.request.urlretrieve(data_url, data_filepath)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/tmp/tfx-datanr9842i4/data.csv', <http.client.HTTPMessage at 0x7f55309481d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpO9jELgxmp5",
        "outputId": "365b8dfb-e211-4b1f-b444-cf98383f4e92"
      },
      "source": [
        "!head {data_filepath}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\n",
            "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\n",
            "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\n",
            "0,0.29818181818181805,0.5833333333333334,0.3898305084745763,0.1527777777777778\n",
            "0,0.16727272727272732,0.7380952380952381,0.3559322033898305,0.20833333333333334\n",
            "0,0.26181818181818167,0.892857142857143,0.3050847457627119,0.2638888888888889\n",
            "0,0.24727272727272717,0.5595238095238096,0.15254237288135594,0.2569444444444444\n",
            "0,0.25818181818181823,0.773809523809524,0.3898305084745763,0.5486111111111112\n",
            "0,0.32727272727272727,0.5357142857142859,0.1694915254237288,0.1388888888888889\n",
            "0,0.23636363636363636,0.9642857142857142,0.3220338983050847,0.3055555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee7EUy0Xx9WL"
      },
      "source": [
        "### Create a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xdWcrpkKOw3"
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('/content/metadata')\n",
        "# shutil.rmtree('/content/pipelines')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS5ZU35CxteS"
      },
      "source": [
        "_trainer_module_file = 'penguin_trainer.py'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2dVSQf_zFCg",
        "outputId": "3ce6c4c7-6c6e-406e-a86c-4943627e3053"
      },
      "source": [
        "%%writefile {_trainer_module_file}\n",
        "\n",
        "\n",
        "from typing import List\n",
        "from absl import logging\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_transform.tf_metadata import schema_utils\n",
        "\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "from tfx.components.trainer.fn_args_utils import DataAccessor\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "_FEATURE_KEYS = [\n",
        "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
        "]\n",
        "_LABEL_KEY = 'species'\n",
        "\n",
        "_TRAIN_BATCH_SIZE = 20\n",
        "_EVAL_BATCH_SIZE = 10\n",
        "\n",
        "_FEATURE_SPEC = {\n",
        "    \n",
        "    **{\n",
        "        feature: tf.io.FixedLenFeature(shape = [1], dtype = tf.float32)\n",
        "          for feature in _FEATURE_KEYS\n",
        "    },\n",
        "\n",
        "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
        "}\n",
        "\n",
        "def _input_fn(file_pattern : List[str],\n",
        "              data_accessor: DataAccessor,\n",
        "              schema: schema_pb2.Schema,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "\n",
        "\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size = batch_size, label_key = _LABEL_KEY),\n",
        "      schema = schema).repeat() \n",
        "\n",
        "\n",
        "def _build_keras_model() -> tf.keras.Model:\n",
        "\n",
        "  inputs = [tf.keras.layers.Input(shape = (1, ), name = f) for f in _FEATURE_KEYS]  \n",
        "\n",
        "  d = tf.keras.layers.concatenate(inputs)   \n",
        "\n",
        "  for _ in range(2):\n",
        "    d = tf.keras.layers.Dense(units = 8, activation = 'relu')(d)\n",
        "\n",
        "  outputs = keras.layers.Dense(3)(d)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n",
        "  \n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(1e-2), \n",
        "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "                metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "  \n",
        "  model.summary(print_fn=logging.info)\n",
        "\n",
        "  return model\n",
        "\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "\n",
        "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
        "\n",
        "  train_dataset = _input_fn(\n",
        "      \n",
        "      fn_args.train_files,\n",
        "      fn_args.data_accessor,\n",
        "      schema,\n",
        "      batch_size = _TRAIN_BATCH_SIZE)\n",
        "  \n",
        "  eval_dataset = _input_fn(\n",
        "    \n",
        "    fn_args.eval_files,\n",
        "    fn_args.data_accessor,\n",
        "    schema,\n",
        "    batch_size = _EVAL_BATCH_SIZE)\n",
        "  \n",
        "  model = _build_keras_model()\n",
        "\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps)\n",
        "\n",
        "\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing penguin_trainer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbKoXiH-GQZq"
      },
      "source": [
        "### Pipeline definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5JadF2zzK6A"
      },
      "source": [
        "from tfx.components import CsvExampleGen\n",
        "from tfx.components import Pusher\n",
        "from tfx.components import Trainer\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.dsl.components.base import executor_spec\n",
        "from tfx.orchestration import metadata\n",
        "from tfx.orchestration import pipeline\n",
        "from tfx.proto import pusher_pb2\n",
        "from tfx.proto import trainer_pb2\n",
        "\n",
        "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
        "                     module_file: str, serving_model_dir: str,\n",
        "                     metadata_path: str) -> pipeline.Pipeline:\n",
        "\n",
        "  example_gen = CsvExampleGen(input_base = data_root)\n",
        "\n",
        "  trainer = Trainer(\n",
        "      module_file = module_file,\n",
        "      custom_executor_spec = executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "      examples=example_gen.outputs['examples'],\n",
        "      train_args=trainer_pb2.TrainArgs(num_steps = 100),\n",
        "      eval_args=trainer_pb2.EvalArgs(num_steps = 5))\n",
        "  \n",
        "  pusher = Pusher(\n",
        "      model=trainer.outputs['model'],\n",
        "      push_destination = pusher_pb2.PushDestination(\n",
        "      filesystem = pusher_pb2.PushDestination.Filesystem(\n",
        "      base_directory = serving_model_dir)))\n",
        "  \n",
        "  components = [\n",
        "      example_gen,\n",
        "      trainer,\n",
        "      pusher,\n",
        "  ]\n",
        "\n",
        "  return pipeline.Pipeline(\n",
        "      pipeline_name = pipeline_name,\n",
        "      pipeline_root = pipeline_root,\n",
        "      metadata_connection_config=metadata.sqlite_metadata_connection_config(\n",
        "          metadata_path),\n",
        "      components=components)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJM6Vt6JIx8B"
      },
      "source": [
        "### Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7MkW740IiNG",
        "outputId": "fdb8dd87-df9b-4751-bbff-aaeb5480f887"
      },
      "source": [
        "import os\n",
        "from tfx.orchestration.local import local_dag_runner\n",
        "\n",
        "\n",
        "local_dag_runner.LocalDagRunner().run(\n",
        "  _create_pipeline(\n",
        "      pipeline_name = PIPELINE_NAME,\n",
        "      pipeline_root = PIPELINE_ROOT,\n",
        "      data_root = DATA_ROOT,\n",
        "      module_file = _trainer_module_file,\n",
        "      serving_model_dir = SERVING_MODEL_DIR,\n",
        "      metadata_path = METADATA_PATH))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`custom_executor_spec` is going to be deprecated.\n",
            "INFO:absl:Generating ephemeral wheel package for '/content/penguin_trainer.py' (including modules: ['penguin_trainer']).\n",
            "INFO:absl:User module package has hash fingerprint version 7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '/tmp/tmpr2jvptrz/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpjbrw1p21', '--dist-dir', '/tmp/tmpp5hlrz6f']\n",
            "INFO:absl:Successfully built user code wheel distribution at 'pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl'; target user module is 'penguin_trainer'.\n",
            "INFO:absl:Full user module path is 'penguin_trainer@pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl'\n",
            "INFO:absl:Running pipeline:\n",
            " pipeline_info {\n",
            "  id: \"penguin-simple\"\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "      }\n",
            "      id: \"CsvExampleGen\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-simple\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-05-18T06:29:59.961661\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-simple.CsvExampleGen\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Examples\"\n",
            "              properties {\n",
            "                key: \"span\"\n",
            "                value: INT\n",
            "              }\n",
            "              properties {\n",
            "                key: \"split_names\"\n",
            "                value: STRING\n",
            "              }\n",
            "              properties {\n",
            "                key: \"version\"\n",
            "                value: INT\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"input_base\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"/tmp/tfx-datanr9842i4\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"input_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"output_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"output_data_format\"\n",
            "        value {\n",
            "          field_value {\n",
            "            int_value: 6\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    downstream_nodes: \"Trainer\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.trainer.component.Trainer\"\n",
            "      }\n",
            "      id: \"Trainer\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-simple\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-05-18T06:29:59.961661\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-simple.Trainer\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"examples\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"CsvExampleGen\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-simple\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-05-18T06:29:59.961661\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-simple.CsvExampleGen\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Examples\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"examples\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"model\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"Model\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      outputs {\n",
            "        key: \"model_run\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"ModelRun\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"custom_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"null\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"eval_args\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"module_path\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"penguin_trainer@pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"train_args\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"CsvExampleGen\"\n",
            "    downstream_nodes: \"Pusher\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "nodes {\n",
            "  pipeline_node {\n",
            "    node_info {\n",
            "      type {\n",
            "        name: \"tfx.components.pusher.component.Pusher\"\n",
            "      }\n",
            "      id: \"Pusher\"\n",
            "    }\n",
            "    contexts {\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-simple\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"pipeline_run\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"2021-05-18T06:29:59.961661\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      contexts {\n",
            "        type {\n",
            "          name: \"node\"\n",
            "        }\n",
            "        name {\n",
            "          field_value {\n",
            "            string_value: \"penguin-simple.Pusher\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    inputs {\n",
            "      inputs {\n",
            "        key: \"model\"\n",
            "        value {\n",
            "          channels {\n",
            "            producer_node_query {\n",
            "              id: \"Trainer\"\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-simple\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"pipeline_run\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"2021-05-18T06:29:59.961661\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            context_queries {\n",
            "              type {\n",
            "                name: \"node\"\n",
            "              }\n",
            "              name {\n",
            "                field_value {\n",
            "                  string_value: \"penguin-simple.Trainer\"\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "            artifact_query {\n",
            "              type {\n",
            "                name: \"Model\"\n",
            "              }\n",
            "            }\n",
            "            output_key: \"model\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    outputs {\n",
            "      outputs {\n",
            "        key: \"pushed_model\"\n",
            "        value {\n",
            "          artifact_spec {\n",
            "            type {\n",
            "              name: \"PushedModel\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    parameters {\n",
            "      parameters {\n",
            "        key: \"custom_config\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"null\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      parameters {\n",
            "        key: \"push_destination\"\n",
            "        value {\n",
            "          field_value {\n",
            "            string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/penguin-simple\\\"\\n  }\\n}\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    upstream_nodes: \"Trainer\"\n",
            "    execution_options {\n",
            "      caching_options {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "runtime_spec {\n",
            "  pipeline_root {\n",
            "    field_value {\n",
            "      string_value: \"pipelines/penguin-simple\"\n",
            "    }\n",
            "  }\n",
            "  pipeline_run_id {\n",
            "    field_value {\n",
            "      string_value: \"2021-05-18T06:29:59.961661\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "execution_mode: SYNC\n",
            "deployment_config {\n",
            "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
            "  value: \"\\n\\220\\001\\n\\007Trainer\\022\\204\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0221\\n/tfx.components.trainer.executor.GenericExecutor\\n\\236\\001\\n\\rCsvExampleGen\\022\\214\\001\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022@\\n>\\n<tfx.components.example_gen.csv_example_gen.executor.Executor\\n\\206\\001\\n\\006Pusher\\022|\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022)\\n\\'tfx.components.pusher.executor.Executor\\022\\230\\001\\n\\rCsvExampleGen\\022\\206\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0223\\n1tfx.components.example_gen.driver.FileBasedDriver*]\\n0type.googleapis.com/ml_metadata.ConnectionConfig\\022)\\032\\'\\n#metadata/penguin-simple/metadata.db\\020\\003\"\n",
            "}\n",
            "\n",
            "INFO:absl:Using deployment config:\n",
            " executor_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    beam_executable_spec {\n",
            "      python_executor_spec {\n",
            "        class_path: \"tfx.components.example_gen.csv_example_gen.executor.Executor\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Pusher\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "executor_specs {\n",
            "  key: \"Trainer\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "custom_driver_specs {\n",
            "  key: \"CsvExampleGen\"\n",
            "  value {\n",
            "    python_class_executable_spec {\n",
            "      class_path: \"tfx.components.example_gen.driver.FileBasedDriver\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "metadata_connection_config {\n",
            "  sqlite {\n",
            "    filename_uri: \"metadata/penguin-simple/metadata.db\"\n",
            "    connection_mode: READWRITE_OPENCREATE\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using connection config:\n",
            " sqlite {\n",
            "  filename_uri: \"metadata/penguin-simple/metadata.db\"\n",
            "  connection_mode: READWRITE_OPENCREATE\n",
            "}\n",
            "\n",
            "INFO:absl:Component CsvExampleGen is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-05-18T06:29:59.961661\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/tmp/tfx-datanr9842i4\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 1\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=1, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-simple/CsvExampleGen/examples/1\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1621316618,sum_checksum:1621316618\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}), exec_properties={'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"*\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 2,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'input_base': '/tmp/tfx-datanr9842i4', 'span': 0, 'version': None, 'input_fingerprint': 'split:single_split,num_files:1,total_bytes:25648,xor_checksum:1621316618,sum_checksum:1621316618'}, execution_output_uri='pipelines/penguin-simple/CsvExampleGen/.system/executor_execution/1/executor_output.pb', stateful_working_dir='pipelines/penguin-simple/CsvExampleGen/.system/stateful_working_dir/2021-05-18T06:29:59.961661', tmp_dir='pipelines/penguin-simple/CsvExampleGen/.system/executor_execution/1/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
            "  }\n",
            "  id: \"CsvExampleGen\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-05-18T06:29:59.961661\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple.CsvExampleGen\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Examples\"\n",
            "          properties {\n",
            "            key: \"span\"\n",
            "            value: INT\n",
            "          }\n",
            "          properties {\n",
            "            key: \"split_names\"\n",
            "            value: STRING\n",
            "          }\n",
            "          properties {\n",
            "            key: \"version\"\n",
            "            value: INT\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"input_base\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"/tmp/tfx-datanr9842i4\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"input_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 2,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"output_data_format\"\n",
            "    value {\n",
            "      field_value {\n",
            "        int_value: 6\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "downstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-simple\"\n",
            ", pipeline_run_id='2021-05-18T06:29:59.961661')\n",
            "INFO:absl:Generating examples.\n",
            "INFO:absl:Processing input csv data /tmp/tfx-datanr9842i4/* to TFExample.\n",
            "INFO:absl:Examples generated.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 1 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"pipelines/penguin-simple/CsvExampleGen/examples/1\"\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1621316618,sum_checksum:1621316618\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"0.30.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}) for execution 1\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component CsvExampleGen is finished.\n",
            "INFO:absl:Component Trainer is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-05-18T06:29:59.961661\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-05-18T06:29:59.961661\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"penguin_trainer@pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 2\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={'examples': [Artifact(artifact: id: 1\n",
            "type_id: 6\n",
            "uri: \"pipelines/penguin-simple/CsvExampleGen/examples/1\"\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value {\n",
            "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"input_fingerprint\"\n",
            "  value {\n",
            "    string_value: \"split:single_split,num_files:1,total_bytes:25648,xor_checksum:1621316618,sum_checksum:1621316618\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:CsvExampleGen:examples:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"payload_format\"\n",
            "  value {\n",
            "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"span\"\n",
            "  value {\n",
            "    int_value: 0\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"0.30.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1621319401447\n",
            "last_update_time_since_epoch: 1621319401447\n",
            ", artifact_type: id: 6\n",
            "name: \"Examples\"\n",
            "properties {\n",
            "  key: \"span\"\n",
            "  value: INT\n",
            "}\n",
            "properties {\n",
            "  key: \"split_names\"\n",
            "  value: STRING\n",
            "}\n",
            "properties {\n",
            "  key: \"version\"\n",
            "  value: INT\n",
            "}\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipelines/penguin-simple/Trainer/model/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Model\"\n",
            ")], 'model_run': [Artifact(artifact: uri: \"pipelines/penguin-simple/Trainer/model_run/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Trainer:model_run:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")]}), exec_properties={'eval_args': '{\\n  \"num_steps\": 5\\n}', 'module_path': 'penguin_trainer@pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 100\\n}', 'custom_config': 'null'}, execution_output_uri='pipelines/penguin-simple/Trainer/.system/executor_execution/2/executor_output.pb', stateful_working_dir='pipelines/penguin-simple/Trainer/.system/stateful_working_dir/2021-05-18T06:29:59.961661', tmp_dir='pipelines/penguin-simple/Trainer/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.trainer.component.Trainer\"\n",
            "  }\n",
            "  id: \"Trainer\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-05-18T06:29:59.961661\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple.Trainer\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"examples\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"CsvExampleGen\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-05-18T06:29:59.961661\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple.CsvExampleGen\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Examples\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"examples\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"Model\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  outputs {\n",
            "    key: \"model_run\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"ModelRun\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"eval_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"module_path\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"penguin_trainer@pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"train_args\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"num_steps\\\": 100\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"CsvExampleGen\"\n",
            "downstream_nodes: \"Pusher\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-simple\"\n",
            ", pipeline_run_id='2021-05-18T06:29:59.961661')\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-ade840be-0542-4957-8086-1ba456e267d3.json']\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.7/dist-packages/tfx to temp dir /tmp/tmpgrs_rqqf/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpgrs_rqqf/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpgrs_rqqf/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpgrs_rqqf/build/tfx/dist/tfx_ephemeral-0.30.0.tar.gz to beam args\n",
            "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
            "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
            "ERROR:absl:udf_utils.get_fn {'eval_args': '{\\n  \"num_steps\": 5\\n}', 'module_path': 'penguin_trainer@pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl', 'train_args': '{\\n  \"num_steps\": 100\\n}', 'custom_config': 'null'} 'run_fn'\n",
            "INFO:absl:Installing 'pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl' to a temporary directory.\n",
            "INFO:absl:Executing: ['/usr/bin/python3', '-m', 'pip', 'install', '--target', '/tmp/tmpe7ht_x2f', 'pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl']\n",
            "INFO:absl:Successfully installed 'pipelines/penguin-simple/_wheels/tfx_user_code_Trainer-0.0+7b935587638635e410ab89a02ad7df911267f263107929df65c985d919bc81b1-py3-none-any.whl'.\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature body_mass_g has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_depth_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature culmen_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature flipper_length_mm has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature species has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Model: \"model_1\"\n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "INFO:absl:==================================================================================================\n",
            "INFO:absl:culmen_length_mm (InputLayer)   [(None, 1)]          0                                            \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:culmen_depth_mm (InputLayer)    [(None, 1)]          0                                            \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:flipper_length_mm (InputLayer)  [(None, 1)]          0                                            \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:body_mass_g (InputLayer)        [(None, 1)]          0                                            \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:concatenate_1 (Concatenate)     (None, 4)            0           culmen_length_mm[0][0]           \n",
            "INFO:absl:                                                                 culmen_depth_mm[0][0]            \n",
            "INFO:absl:                                                                 flipper_length_mm[0][0]          \n",
            "INFO:absl:                                                                 body_mass_g[0][0]                \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:dense_3 (Dense)                 (None, 8)            40          concatenate_1[0][0]              \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:dense_4 (Dense)                 (None, 8)            72          dense_3[0][0]                    \n",
            "INFO:absl:__________________________________________________________________________________________________\n",
            "INFO:absl:dense_5 (Dense)                 (None, 3)            27          dense_4[0][0]                    \n",
            "INFO:absl:==================================================================================================\n",
            "INFO:absl:Total params: 139\n",
            "INFO:absl:Trainable params: 139\n",
            "INFO:absl:Non-trainable params: 0\n",
            "INFO:absl:__________________________________________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 5ms/step - loss: 0.7655 - sparse_categorical_accuracy: 0.7045 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9800\n",
            "INFO:tensorflow:Assets written to: pipelines/penguin-simple/Trainer/model/2/Format-Serving/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: pipelines/penguin-simple/Trainer/model/2/Format-Serving/assets\n",
            "INFO:absl:Training complete. Model written to pipelines/penguin-simple/Trainer/model/2/Format-Serving. ModelRun written to pipelines/penguin-simple/Trainer/model_run/2\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 2 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'model': [Artifact(artifact: uri: \"pipelines/penguin-simple/Trainer/model/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"0.30.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"Model\"\n",
            ")], 'model_run': [Artifact(artifact: uri: \"pipelines/penguin-simple/Trainer/model_run/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Trainer:model_run:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"0.30.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"ModelRun\"\n",
            ")]}) for execution 2\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Trainer is finished.\n",
            "INFO:absl:Component Pusher is running.\n",
            "INFO:absl:Running launcher for node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.pusher.component.Pusher\"\n",
            "  }\n",
            "  id: \"Pusher\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-05-18T06:29:59.961661\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple.Pusher\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-05-18T06:29:59.961661\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"pushed_model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"PushedModel\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"push_destination\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/penguin-simple\\\"\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Going to run a new execution 3\n",
            "INFO:absl:Going to run a new execution: ExecutionInfo(execution_id=3, input_dict={'model': [Artifact(artifact: id: 2\n",
            "type_id: 8\n",
            "uri: \"pipelines/penguin-simple/Trainer/model/2\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Trainer:model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"0.30.0\"\n",
            "  }\n",
            "}\n",
            "state: LIVE\n",
            "create_time_since_epoch: 1621319408761\n",
            "last_update_time_since_epoch: 1621319408761\n",
            ", artifact_type: id: 8\n",
            "name: \"Model\"\n",
            ")]}, output_dict=defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/penguin-simple/Pusher/pushed_model/3\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Pusher:pushed_model:0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"PushedModel\"\n",
            ")]}), exec_properties={'custom_config': 'null', 'push_destination': '{\\n  \"filesystem\": {\\n    \"base_directory\": \"serving_model/penguin-simple\"\\n  }\\n}'}, execution_output_uri='pipelines/penguin-simple/Pusher/.system/executor_execution/3/executor_output.pb', stateful_working_dir='pipelines/penguin-simple/Pusher/.system/stateful_working_dir/2021-05-18T06:29:59.961661', tmp_dir='pipelines/penguin-simple/Pusher/.system/executor_execution/3/.temp/', pipeline_node=node_info {\n",
            "  type {\n",
            "    name: \"tfx.components.pusher.component.Pusher\"\n",
            "  }\n",
            "  id: \"Pusher\"\n",
            "}\n",
            "contexts {\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"pipeline_run\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"2021-05-18T06:29:59.961661\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  contexts {\n",
            "    type {\n",
            "      name: \"node\"\n",
            "    }\n",
            "    name {\n",
            "      field_value {\n",
            "        string_value: \"penguin-simple.Pusher\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "inputs {\n",
            "  inputs {\n",
            "    key: \"model\"\n",
            "    value {\n",
            "      channels {\n",
            "        producer_node_query {\n",
            "          id: \"Trainer\"\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"pipeline_run\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"2021-05-18T06:29:59.961661\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        context_queries {\n",
            "          type {\n",
            "            name: \"node\"\n",
            "          }\n",
            "          name {\n",
            "            field_value {\n",
            "              string_value: \"penguin-simple.Trainer\"\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        artifact_query {\n",
            "          type {\n",
            "            name: \"Model\"\n",
            "          }\n",
            "        }\n",
            "        output_key: \"model\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "outputs {\n",
            "  outputs {\n",
            "    key: \"pushed_model\"\n",
            "    value {\n",
            "      artifact_spec {\n",
            "        type {\n",
            "          name: \"PushedModel\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "parameters {\n",
            "  parameters {\n",
            "    key: \"custom_config\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"null\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  parameters {\n",
            "    key: \"push_destination\"\n",
            "    value {\n",
            "      field_value {\n",
            "        string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"serving_model/penguin-simple\\\"\\n  }\\n}\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "upstream_nodes: \"Trainer\"\n",
            "execution_options {\n",
            "  caching_options {\n",
            "  }\n",
            "}\n",
            ", pipeline_info=id: \"penguin-simple\"\n",
            ", pipeline_run_id='2021-05-18T06:29:59.961661')\n",
            "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/root/.local/share/jupyter/runtime/kernel-ade840be-0542-4957-8086-1ba456e267d3.json']\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.7/dist-packages/tfx to temp dir /tmp/tmp_1o06yd3/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp_1o06yd3/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp_1o06yd3/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp_1o06yd3/build/tfx/dist/tfx_ephemeral-0.30.0.tar.gz to beam args\n",
            "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n",
            "INFO:absl:Model version: 1621319410\n",
            "INFO:absl:Model written to serving path serving_model/penguin-simple/1621319410.\n",
            "INFO:absl:Model pushed to pipelines/penguin-simple/Pusher/pushed_model/3.\n",
            "INFO:absl:Cleaning up stateless execution info.\n",
            "INFO:absl:Execution 3 succeeded.\n",
            "INFO:absl:Cleaning up stateful execution info.\n",
            "INFO:absl:Publishing output artifacts defaultdict(<class 'list'>, {'pushed_model': [Artifact(artifact: uri: \"pipelines/penguin-simple/Pusher/pushed_model/3\"\n",
            "custom_properties {\n",
            "  key: \"name\"\n",
            "  value {\n",
            "    string_value: \"penguin-simple:2021-05-18T06:29:59.961661:Pusher:pushed_model:0\"\n",
            "  }\n",
            "}\n",
            "custom_properties {\n",
            "  key: \"tfx_version\"\n",
            "  value {\n",
            "    string_value: \"0.30.0\"\n",
            "  }\n",
            "}\n",
            ", artifact_type: name: \"PushedModel\"\n",
            ")]}) for execution 3\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Pusher is finished.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKvIslB-JkSh",
        "outputId": "eeb0bb76-be11-4d1c-b936-78e979d4518c"
      },
      "source": [
        "!find {SERVING_MODEL_DIR}\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "serving_model/penguin-simple\n",
            "serving_model/penguin-simple/1621319410\n",
            "serving_model/penguin-simple/1621319410/variables\n",
            "serving_model/penguin-simple/1621319410/variables/variables.index\n",
            "serving_model/penguin-simple/1621319410/variables/variables.data-00000-of-00001\n",
            "serving_model/penguin-simple/1621319410/saved_model.pb\n",
            "serving_model/penguin-simple/1621319410/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ognk9YtP91W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}